# plugins/face_recognizer.py
import cv2
import numpy as np
from typing import Dict, List, Optional
import pickle
import logging
from fastapi import UploadFile, File, APIRouter
from facenet_pytorch import MTCNN, InceptionResnetV1

@dataclass
class Face:
    identity: str
    confidence: float
    bbox: List[int]  # [x1, y1, x2, y2]
    embedding: List[float]

class FaceRecognizer:
    def __init__(self):
        # Initialize models
        self.mtcnn = MTCNN(keep_all=True, device="cpu")
        self.resnet = InceptionResnetV1(pretrained="vggface2").eval()
        self.knn = self._load_knn_model()
        
    def _load_knn_model(self):
        """Load pre-trained KNN classifier"""
        try:
            with open("models/face_knn.pkl", "rb") as f:
                return pickle.load(f)
        except:
            logging.warning("No KNN model found - recognition disabled")
            return None

    async def recognize_faces(self, image: UploadFile) -> List[Face]:
        """Detect and identify faces"""
        try:
            img = await self._file_to_cv2(image)
            faces = self._detect_faces(img)
            return self._identify_faces(faces, img)
        except Exception as e:
            logging.error(f"Face recognition failed: {str(e)}")
            raise

    def _detect_faces(self, img: np.ndarray) -> List[List[int]]:
        """MTCNN face detection"""
        boxes, _ = self.mtcnn.detect(img)
        return boxes.tolist() if boxes is not None else []

    def _identify_faces(self, boxes: List, img: np.ndarray) -> List[Face]:
        """FaceNet embedding + KNN classification"""
        faces = []
        for box in boxes:
            face_img = img[int(box[1]):int(box[3]), int(box[0]):int(box[2])]
            embedding = self._get_embedding(face_img)
            
            identity = "unknown"
            confidence = 0.0
            
            if self.knn:
                embedding_reshaped = embedding.reshape(1, -1)
                distances, indices = self.knn.kneighbors(embedding_reshaped)
                if distances[0][0] < 0.6:  # Threshold
                    identity = self.knn.classes_[indices[0][0]]
                    confidence = 1 - distances[0][0]
            
            faces.append(Face(
                identity=identity,
                confidence=confidence,
                bbox=box,
                embedding=embedding.tolist()
            ))
        return faces

    def _get_embedding(self, face_img: np.ndarray) -> np.ndarray:
        """Generate FaceNet embedding"""
        face = cv2.resize(face_img, (160, 160))
        face = torch.from_numpy(face).float()
        face = (face - 127.5) / 128.0  # Normalization
        return self.resnet(face.unsqueeze(0)).detach().numpy()

# FastAPI Endpoint
router = APIRouter()
recognizer = FaceRecognizer()

@router.post("/recognize")
async def recognize_faces(image: UploadFile = File(...)):
    return await recognizer.recognize_faces(image)